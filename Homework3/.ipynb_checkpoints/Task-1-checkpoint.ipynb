{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "from torch.nn import Sigmoid\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data\n",
    "dataset_path = '~/datasets'\n",
    "batch_size = 100\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "\n",
    "train_dataset = MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
    "test_dataset = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "train_data = torch.utils.data.Subset(train_dataset, range(0,50000))\n",
    "val_data = torch.utils.data.Subset(train_dataset, range(50000, 60000))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "vali_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=True,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "    \n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x[:, :, :28, :28]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(3,3), stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(3, 3),  padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1),  padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.z_mean = torch.nn.Linear(8*8*64, 10)\n",
    "        self.z_var =nn.Sequential(\n",
    "            torch.nn.Linear(8*8*64, 10),\n",
    "            torch.nn.Softplus())\n",
    "\n",
    "\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.Linear(10, 8*8*64),\n",
    "            Reshape(-1, 64, 8, 8),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=(3, 3), stride = (1, 1),  padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),            \n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=(3, 3), stride = (3, 3),  padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(3, 3), stride = (1, 1),  padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # 2 output channels, one for mu one for sigma\n",
    "            # alternatively one for beta one for alpha\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=(3, 3), stride = (1, 1), padding=0),\n",
    "            # this for gauss\n",
    "            # nn.Sigmoid()\n",
    "            # this for beta\n",
    "            Trim(),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def reparametization(self, z_mu, z_var):\n",
    "        #batch_mu_z + torch.sqrt(batch_var_z) * torch.randn(batch_var_z.shape, device=device)\n",
    "        z = z_mu + torch.sqrt(z_var)*torch.randn(z_var.shape,device=device)\n",
    "        #eps = torch.randn_like(torch.exp(z_log_var),device=device)\n",
    "        #z = z_mu + torch.exp(z_log_var) * eps\n",
    "\n",
    "        return z\n",
    "  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_var = self.z_mean(x), self.z_var(x)\n",
    "        encoded = self.reparametization(z_mean, z_var)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, z_mean, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE().to(device)\n",
    "\n",
    "def loss_function(x, x_reconstr, mu, log_sigma):\n",
    "    reconstr_loss = nn.functional.mse_loss(x_reconstr, x, reduction='sum')\n",
    "    kl_loss = 0.5 * torch.sum(mu.pow(2) + (2*log_sigma).exp() - 2*log_sigma - 1)\n",
    "    total_loss = reconstr_loss + kl_loss\n",
    "    return total_loss, reconstr_loss, kl_loss\n",
    "\n",
    "optimizer = Adam(vae.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "print(\"Start training VAE...\")\n",
    "start_time = time.time()\n",
    "vae.train()\n",
    "\n",
    "train_ELBO = []\n",
    "validation_ELBO = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    overall_loss = 0\n",
    "    overall_reconstr_loss = 0\n",
    "    overall_kl_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        x_reconstr, mu, log_sigma = vae(x)\n",
    "        loss, reconstr_loss, kl_loss = loss_function(x, x_reconstr, mu, log_sigma)\n",
    "        overall_loss += loss.item()\n",
    "        overall_reconstr_loss += reconstr_loss.item()\n",
    "        overall_kl_loss += kl_loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "    n_datapoints = batch_idx * batch_size\n",
    "    train_ELBO.append(overall_loss/n_datapoints)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        validation_reconstr_loss = 0\n",
    "        validation_kl_loss = 0\n",
    "        for batch_idx, (x, y) in enumerate(vali_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x_reconstr, mu, log_sigma = vae(x)\n",
    "            loss, reconstr_loss, kl_loss = loss_function(x, x_reconstr, mu, log_sigma)\n",
    "            \n",
    "            validation_loss += loss.item()\n",
    "            validation_reconstr_loss += reconstr_loss.item()\n",
    "            validation_kl_loss += kl_loss.item()\n",
    "            \n",
    "        n_datapoints = batch_idx * batch_size\n",
    "        validation_ELBO.append(validation_loss/n_datapoints)\n",
    "            \n",
    "    if (np.absolute(train_ELBO[epoch] - train_ELBO[epoch-1]) <= 0.05) and (epoch != 0):\n",
    "        print(train_ELBO)\n",
    "        break\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / n_datapoints, \"\\tReconstruction Loss:\", overall_reconstr_loss / n_datapoints, \"\\tKL Loss:\", overall_kl_loss / n_datapoints)\n",
    "    \n",
    "print(\"Training complete!\")\n",
    "print(start_time - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the ELBO plots\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.plot(train_ELBO)\n",
    "ax2.plot(validation_ELBO);\n",
    "ax1.set_xlabel('nr epochs')\n",
    "ax2.set_xlabel('nr epochs')\n",
    "ax1.set_ylabel('loss');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making reconstructions based on the test set\n",
    "vae.eval()\n",
    "\n",
    "x_original_list = []\n",
    "y_list = []\n",
    "x_reconstr_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(test_loader)):\n",
    "        x = x.view(batch_size,1,28,28)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        x_reconstr, mu, log_sigma= vae(x)\n",
    "        x_original_list.append(x)\n",
    "        y_list.append(y)\n",
    "        x_reconstr_list.append(x_reconstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating images\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(batch_size, 10).to(device)\n",
    "    generated_images = vae.decoder(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Making columns of images \n",
    "def show_images(x, ncols=16):\n",
    "    x = x.view(batch_size, 28, 28)\n",
    "    fig, ax = plt.subplots(1, ncols, figsize=(40, 2))\n",
    "    \n",
    "    for idx in range(ncols):\n",
    "        ax[idx].imshow(x[idx].cpu().numpy(), cmap=\"Greys_r\")\n",
    "        ax[idx].axis('off')\n",
    "    time =  datetime.now().strftime('%H%M%S')\n",
    "    fig.savefig(f'figure: {time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "show_images(x_original_list[batch_idx])\n",
    "show_images(x_reconstr_list[batch_idx])\n",
    "show_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
